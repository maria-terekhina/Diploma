{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import textgrid\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocParser(object):\n",
    "    def __init__(self, lang):        \n",
    "        self.lang = lang\n",
    "        \n",
    "    def parse(self, xml, name):\n",
    "        if self.lang == 'Bashkir':\n",
    "            return self._get_data_bashkir(xml)\n",
    "        \n",
    "        elif self.lang == 'Beserman' or self.lang == 'Chukchi':\n",
    "            return self._get_data_beserman(xml)\n",
    "               \n",
    "        elif self.lang == 'Azeri':\n",
    "            return self._get_data_azeri(xml, name)\n",
    "        \n",
    "        elif self.lang == 'Kabardian':\n",
    "            return self._get_data_kabardian(xml)\n",
    "        \n",
    "        elif self.lang in {'Ustja', 'Rogovatka', 'Malinino', 'Opochka'}:\n",
    "            return self._get_data_rogovatka(xml, name)\n",
    "        \n",
    "    def __calculate_syllables(self, text):\n",
    "        if text is None:\n",
    "            return 0\n",
    "        if self.lang == 'Beserman' or self.lang == 'Chukchi':\n",
    "            vowels = {'o', 'e', 'a', 'i', 'ə', 'u'}\n",
    "        elif self.lang == 'Bashkir':\n",
    "            vowels = {'o', 'e', 'a', 'i', 'ə', 'u', 'ö', 'ä'}\n",
    "        elif self.lang in {'Ustja', 'Rogovatka', 'Malinino', 'Opochka'}:\n",
    "            vowels = {'у', 'е', 'ы', 'а', 'о', 'э', 'я', 'и', 'ю', 'ё'}\n",
    "        elif self.lang == 'Azeri':\n",
    "            vowels = {'o', 'e', 'a', 'i', 'ə', 'u', 'ü', 'ö'}\n",
    "        elif self.lang == 'Kabardian':\n",
    "            vowels = {'э', 'ы', 'а', 'и', 'е', 'y', 'я', 'о', 'ю', 'ё', 'ə', 'e', 'a', 'o', 'u', 'у'}\n",
    "\n",
    "        n_syl = 0\n",
    "\n",
    "        for char in text:\n",
    "            if char.lower() in vowels:\n",
    "                n_syl += 1\n",
    "            elif self.lang != 'Kabardian' and char in {'(', ')', '[', ']', '<', '>'}:\n",
    "                return 0\n",
    "\n",
    "        return n_syl\n",
    "    def _get_data_rogovatka(self, xml, name):\n",
    "        soup = bs(xml, 'xml')\n",
    "        r_year = re.search('(20..)', name)\n",
    "        if r_year is not None:\n",
    "            r_year = int(r_year.groups(0)[0])\n",
    "        else:\n",
    "            r_year = 0\n",
    "        tiers = soup.find_all('TIER', LINGUISTIC_TYPE_REF='Praat')\n",
    "        tiers += soup.find_all('TIER', LINGUISTIC_TYPE_REF='default-lt')\n",
    "\n",
    "        new_data = list()\n",
    "\n",
    "        for t in tiers:\n",
    "            part = t.attrs['TIER_ID']\n",
    "            expressions = t.find_all('ALIGNABLE_ANNOTATION')\n",
    "            for exp in expressions:\n",
    "                data = dict()\n",
    "                data['PARTICIPANT'] = part\n",
    "                data['R_YEAR'] = r_year\n",
    "                start_id = exp.attrs['TIME_SLOT_REF1']\n",
    "                end_id = exp.attrs['TIME_SLOT_REF2']\n",
    "\n",
    "                start_time = int(soup.find('TIME_SLOT', TIME_SLOT_ID=start_id).attrs['TIME_VALUE'])\n",
    "                end_time = int(soup.find('TIME_SLOT', TIME_SLOT_ID=end_id).attrs['TIME_VALUE'])\n",
    "\n",
    "                data['DURATION'] = end_time - start_time\n",
    "                for c in exp.find('ANNOTATION_VALUE'):\n",
    "                    data['TEXT'] = c\n",
    "                    data['SYLLABLES'] = self.__calculate_syllables(c)\n",
    "                    data['RATE'] = data['SYLLABLES'] / (data['DURATION'] / 1000)\n",
    "                if 'TEXT' in data:\n",
    "                    new_data.append(data)\n",
    "\n",
    "        return new_data\n",
    "    \n",
    "    def _get_data_azeri(self, xml, name):\n",
    "        tg = textgrid.TextGrid(xml)\n",
    "        new_data = list()\n",
    "        \n",
    "        for tier in tg.tiers:\n",
    "            if 'ransc' in tier.nameid:\n",
    "                part = tier.nameid\n",
    "                for exp in tier.simple_transcript:\n",
    "                    if exp[2] != '' and re.search('[а-я]', exp[2]) is None:                        \n",
    "                        data = dict()\n",
    "                        data['TEXT'] = exp[2]                       \n",
    "                        data['PARTICIPANT'] = part\n",
    "                        data['DURATION'] = (float(exp[1]) - float(exp[0])) * 1000\n",
    "                        data['SYLLABLES'] = self.__calculate_syllables(exp[2])\n",
    "                        if data['SYLLABLES'] != 0:\n",
    "                            data['RATE'] = data['SYLLABLES'] / (data['DURATION'] / 1000)\n",
    "                            data['R_YEAR'] = '20' + name[4:6]\n",
    "                            new_data.append(data)\n",
    "        return new_data   \n",
    "    \n",
    "    def __find_year(self, soup):\n",
    "        link = soup.find('MEDIA_DESCRIPTOR').attrs['MEDIA_URL']\n",
    "        r_year = re.search('(20..)', link)\n",
    "        if r_year is not None:\n",
    "            return int(r_year.groups(0)[0])\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "    def _get_data_ustja(self, xml):\n",
    "        soup = bs(xml, 'xml')\n",
    "\n",
    "        tiers = soup.find_all('TIER', LINGUISTIC_TYPE_REF='Praat')\n",
    "\n",
    "        new_data = list()\n",
    "\n",
    "        for t in tiers:\n",
    "            part = t.attrs['TIER_ID']\n",
    "\n",
    "            expressions = t.find_all('ALIGNABLE_ANNOTATION')\n",
    "            for exp in expressions:\n",
    "                data = dict()\n",
    "                data['PARTICIPANT'] = part\n",
    "                start_id = exp.attrs['TIME_SLOT_REF1']\n",
    "                end_id = exp.attrs['TIME_SLOT_REF2']\n",
    "\n",
    "                start_time = int(soup.find('TIME_SLOT', TIME_SLOT_ID=start_id).attrs['TIME_VALUE'])\n",
    "                end_time = int(soup.find('TIME_SLOT', TIME_SLOT_ID=end_id).attrs['TIME_VALUE'])\n",
    "\n",
    "                data['DURATION'] = end_time - start_time\n",
    "                for c in exp.find('ANNOTATION_VALUE'):\n",
    "                    data['TEXT'] = c\n",
    "                    data['SYLLABLES'] = self.__calculate_syllables(c)\n",
    "                    data['RATE'] = data['SYLLABLES'] / (data['DURATION'] / 1000)\n",
    "                    \n",
    "                new_data.append(data)\n",
    "\n",
    "        return new_data\n",
    "\n",
    "    def _get_data_beserman(self, xml):\n",
    "        soup = bs(xml, 'xml')\n",
    "\n",
    "        tiers = soup.find_all('TIER', PARTICIPANT=True, LINGUISTIC_TYPE_REF='orig')\n",
    "        tiers += soup.find_all('TIER', PARTICIPANT=True, LINGUISTIC_TYPE_REF='default-lt')\n",
    "        \n",
    "        year = self.__find_year(soup)\n",
    "        new_data = list()\n",
    "        \n",
    "        for t in tiers:\n",
    "            part = t.attrs['PARTICIPANT']\n",
    "\n",
    "            expressions = t.find_all('ALIGNABLE_ANNOTATION')\n",
    "            for exp in expressions:\n",
    "                if re.search('[а-я]', exp.text) is None:\n",
    "                    data = dict()\n",
    "                    data['PARTICIPANT'] = part\n",
    "                    start_id = exp.attrs['TIME_SLOT_REF1']\n",
    "                    end_id = exp.attrs['TIME_SLOT_REF2']\n",
    "\n",
    "                    start_time = int(soup.find('TIME_SLOT', TIME_SLOT_ID=start_id).attrs['TIME_VALUE'])\n",
    "                    end_time = int(soup.find('TIME_SLOT', TIME_SLOT_ID=end_id).attrs['TIME_VALUE'])\n",
    "\n",
    "                    data['R_YEAR'] = year\n",
    "                    data['DURATION'] = end_time - start_time\n",
    "                    for c in exp.find('ANNOTATION_VALUE'):\n",
    "                        data['TEXT'] = c\n",
    "                        data['SYLLABLES'] = self.__calculate_syllables(c)\n",
    "                        data['RATE'] = data['SYLLABLES'] / (data['DURATION'] / 1000)\n",
    "                    new_data.append(data)\n",
    "        return new_data\n",
    "    \n",
    "    def _get_data_kabardian(self,xml):\n",
    "        soup = bs(xml, 'xml')\n",
    "\n",
    "        tiers = soup.find_all('TIER', LINGUISTIC_TYPE_REF='default-lt', PARTICIPANT=True)\n",
    "        new_data = list()\n",
    "        \n",
    "        for t in tiers:\n",
    "            part = t.attrs['PARTICIPANT']\n",
    "\n",
    "            expressions = t.find_all('ALIGNABLE_ANNOTATION')\n",
    "            for exp in expressions:\n",
    "                    data = dict()\n",
    "                    data['PARTICIPANT'] = part\n",
    "                    start_id = exp.attrs['TIME_SLOT_REF1']\n",
    "                    end_id = exp.attrs['TIME_SLOT_REF2']\n",
    "\n",
    "                    start_time = int(soup.find('TIME_SLOT', TIME_SLOT_ID=start_id).attrs['TIME_VALUE'])\n",
    "                    end_time = int(soup.find('TIME_SLOT', TIME_SLOT_ID=end_id).attrs['TIME_VALUE'])\n",
    "\n",
    "                    data['DURATION'] = end_time - start_time\n",
    "                    for c in exp.find('ANNOTATION_VALUE'):\n",
    "                        data['TEXT'] = c\n",
    "                        data['SYLLABLES'] = self.__calculate_syllables(c)\n",
    "                        data['RATE'] = data['SYLLABLES'] / (data['DURATION'] / 1000)\n",
    "                    new_data.append(data)\n",
    "        return new_data\n",
    "    \n",
    "    def _get_data_bashkir(self, xml):\n",
    "        soup = bs(xml, 'xml')\n",
    "\n",
    "        tiers = soup.find_all('TIER', PARTICIPANT=True, LINGUISTIC_TYPE_REF='id')\n",
    "\n",
    "        new_data = list()\n",
    "\n",
    "        for t in tiers:\n",
    "            part = t.attrs['PARTICIPANT']\n",
    "            expressions = t.find_all('ALIGNABLE_ANNOTATION')\n",
    "\n",
    "            for exp in expressions:                \n",
    "                data = dict()\n",
    "                data['PARTICIPANT'] = part\n",
    "                start_id = exp.attrs['TIME_SLOT_REF1']\n",
    "                end_id = exp.attrs['TIME_SLOT_REF2']\n",
    "\n",
    "                start_time = int(soup.find('TIME_SLOT', TIME_SLOT_ID=start_id).attrs['TIME_VALUE'])\n",
    "                end_time = int(soup.find('TIME_SLOT', TIME_SLOT_ID=end_id).attrs['TIME_VALUE'])\n",
    "\n",
    "                data['DURATION'] = end_time - start_time\n",
    "\n",
    "                ann_id = exp.attrs['ANNOTATION_ID']\n",
    "\n",
    "                texts = soup.find('TIER', PARTICIPANT=part, LINGUISTIC_TYPE_REF='tx')            \n",
    "                relevant = texts.find_all('REF_ANNOTATION', ANNOTATION_REF=ann_id)\n",
    "\n",
    "                text = ''\n",
    "                for word in relevant:\n",
    "                    expressions = word.find('ANNOTATION_VALUE')\n",
    "                    text += expressions.text\n",
    "                    text += ' '\n",
    "\n",
    "                    if re.search('[а-я]+', text) is not None: continue\n",
    "                        \n",
    "                    data['TEXT'] = text[:-1]\n",
    "                    data['SYLLABLES'] = self.__calculate_syllables(text[:-1])\n",
    "                    data['RATE'] = data['SYLLABLES'] / (data['DURATION'] / 1000)\n",
    "                    \n",
    "                new_data.append(data)\n",
    "        return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollector(object):\n",
    "    def __init__(self, lang):\n",
    "        self.lang = lang\n",
    "        self.meta = pd.read_csv(r'.\\Data\\Meta' + os.sep + self.lang + '.csv', sep=';', encoding='utf-8')\n",
    "        self.parser = DocParser(lang)\n",
    "        \n",
    "    def get_data(self):\n",
    "        frames = self._collect_data()\n",
    "        long = self._select_long(frames)\n",
    "        data = self._process_long(long, frames)\n",
    "        return data\n",
    "    \n",
    "    def _collect_data(self):\n",
    "        frames = dict()\n",
    "        if self.lang in {'Beserman', 'Bashkir', 'Chukchi', 'Ustja', 'Kabardian', 'Rogovatka'}:\n",
    "            for root, dirs, files in os.walk(r'C:\\Users\\Masha\\Documents\\Diploma\\Data' + os.sep + self.lang):\n",
    "                for name in tqdm_notebook(files):\n",
    "                    if '.eaf' in name:\n",
    "                        with open(root + os.sep + name, 'r', encoding='utf-8') as f:\n",
    "                            xml = f.read()\n",
    "                            data = self.parser.parse(xml, name)\n",
    "                            frame = pd.DataFrame(data, columns=['PARTICIPANT', 'TEXT', 'DURATION', 'SYLLABLES', \n",
    "                                                                'RATE', 'R_YEAR'])\n",
    "                            frames[name] = frame\n",
    "                                \n",
    "        elif self.lang == 'Azeri':\n",
    "            for root, dirs, files in os.walk(r'C:\\Users\\Masha\\Documents\\Diploma\\Data' + os.sep + 'Azeri'):\n",
    "                for name in tqdm_notebook(files):\n",
    "                    if '.TextGrid' in name:\n",
    "                        with open(root + os.sep + name, 'r', encoding='utf-8') as f:\n",
    "                            xml = f.read()\n",
    "                            data = self.parser.parse(xml, name)\n",
    "                            frame = pd.DataFrame(data, columns=['PARTICIPANT', 'TEXT', 'DURATION', 'SYLLABLES', \n",
    "                                                                'RATE', 'R_YEAR'])\n",
    "                            frames[name] = frame\n",
    "        return frames\n",
    "    \n",
    "    def _select_long(self, frames):    \n",
    "\n",
    "        all_participants = dict()\n",
    "        i = 0\n",
    "        \n",
    "        for key in frames:\n",
    "            frame = frames[key]\n",
    "            speech_duration = frame.DURATION.sum()\n",
    "            for participant in set(frame.PARTICIPANT.values):  \n",
    "                p_duration = frame[frame.PARTICIPANT == participant].DURATION.sum()\n",
    "                p_part = p_duration / speech_duration\n",
    "\n",
    "                if p_part >= 0.7:\n",
    "                    all_participants[i] = {'Name': participant, 'File Name': key, 'Duration': p_duration/1000, \n",
    "                                           'Part': p_part, 'Lang': self.lang}\n",
    "                    i += 1\n",
    "        return pd.DataFrame(all_participants).T\n",
    "    \n",
    "    def _process_long(self, long, frames):\n",
    "        long_frames = pd.DataFrame(columns=['PARTICIPANT', 'TEXT', 'DURATION', 'SYLLABLES', 'RATE', 'R_YEAR', 'AGE', 'GENDER',\n",
    "                                           'LANGUAGE', 'FILE'])\n",
    "\n",
    "        for key in frames:\n",
    "                if key in long['File Name'].values:\n",
    "                    part = long[long['File Name'] == key].Name.values[0]\n",
    "                    \n",
    "                    f = frames[key][frames[key].PARTICIPANT == part]\n",
    "                    if self.lang == 'Azeri':\n",
    "                        age, gen, part = self.__get_meta(part, frames[key].R_YEAR.values[0], key)\n",
    "                        f['PARTICIPANT'] = [part] * len(f)\n",
    "                    else:\n",
    "                        age, gen = self.__get_meta(part, frames[key].R_YEAR.values[0], key)\n",
    "                    f['AGE'] = [age] * len(f)\n",
    "                    f['GENDER'] = [gen] * len(f)\n",
    "                    f['LANGUAGE'] = [self.lang] * len(f)\n",
    "                    f['FILE'] = [key] * len(f)\n",
    "                    \n",
    "                       \n",
    "                    long_frames = long_frames.append(f[f.SYLLABLES != 0])\n",
    "                    \n",
    "        return long_frames\n",
    "    \n",
    "    def __get_meta(self, part, year, file):\n",
    "        if self.lang == 'Beserman':\n",
    "            age = year - self.meta[self.meta['Name'] == part]['Year'].values[0]\n",
    "            gen = self.meta[self.meta['Name'] == part]['Gender'].values[0]\n",
    "        \n",
    "        if self.lang == 'Chukchi':\n",
    "            age = self.meta[self.meta['Name'] == part][self.meta['File'] == file]['Record'].values[0] \\\n",
    "            - self.meta[self.meta['Name'] == part][self.meta['File'] == file]['Year'].values[0]\n",
    "            gen = self.meta[self.meta['Name'] == part][self.meta['File'] == file]['Gender'].values[0]\n",
    "            \n",
    "        if self.lang == 'Azeri':\n",
    "            age = self.meta[self.meta['File'] == file]['Record'].values[0] \\\n",
    "            - self.meta[self.meta['File'] == file]['Year'].values[0]\n",
    "            gen = self.meta[self.meta['File'] == file]['Gender'].values[0]\n",
    "            part = self.meta[self.meta['File'] == file]['Name'].values[0]\n",
    "            return age, gen, part\n",
    "            \n",
    "        if self.lang == 'Bashkir':\n",
    "            file = file[:-4]\n",
    "            age = self.meta[self.meta['Name'] == part][self.meta['File'] == file]['Age'].values[0]\n",
    "            gen = self.meta[self.meta['Name'] == part][self.meta['File'] == file]['Gender'].values[0]\n",
    "            gen = gen.capitalize()\n",
    "            \n",
    "        if self.lang == 'Ustja':\n",
    "            age = int(year - self.meta[self.meta['Speaker'] == part]['Year of birth'].values[0])\n",
    "            gen = self.meta[self.meta['Speaker'] == part]['Sex'].values[0]\n",
    "            gen = gen[0].capitalize()\n",
    "            \n",
    "        if self.lang == 'Rogovatka':\n",
    "            age = year - self.meta[self.meta['string_id'] == part]['year_of_birth'].values[0]\n",
    "            gen = self.meta[self.meta['string_id'] == part]['sex'].values[0]\n",
    "            gen = gen.capitalize()\n",
    "            \n",
    "        if self.lang == 'Kabardian':\n",
    "            age = 0\n",
    "            gen = self.meta[self.meta['Name'] == part]['Gender'].values[0]\n",
    "            \n",
    "        return age, gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame(columns=['PARTICIPANT', 'TEXT', 'DURATION', 'SYLLABLES', 'RATE', 'R_YEAR', 'AGE',\n",
    "       'GENDER', 'LANGUAGE', 'FILE'])\n",
    "\n",
    "for lang in ['Beserman', 'Bashkir', 'Chukchi', 'Azeri', 'Ustja', 'Kabardian', 'Rogovatka']:\n",
    "    dc = DataCollector(lang)\n",
    "    data = dc.get_data()\n",
    "    all_data = all_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('all_data.csv', index=False, sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = all_data[all_data['RATE'] < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.to_csv('clean_data.csv', index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
